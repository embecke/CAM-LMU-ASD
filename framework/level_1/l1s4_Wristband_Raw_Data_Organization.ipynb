{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2140f0e2-ab4f-40c2-8b54-ddfdc9b6851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScript 4: wristband data (mainly: electrodermal activity. Can be modified later on to add other measures if required)\\nReading the raw files from avro to csv\\nExtracting aggr eda, temp and acc (these can be used for plotting or other analyses as required)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "level 1\n",
    "Script 4: wristband data (mainly: electrodermal activity. Can be modified later on to add other measures if required)\n",
    "Reading the raw files from avro to csv\n",
    "Extracting aggr eda, temp and acc (these can be used for plotting or other analyses as required)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209f2bc6-a714-438b-9193-5406a65d84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061de287-77e1-4150-a2e9-2c641e1c89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Then functions\n",
    "\"\"\"\n",
    "def utc_cet(utc):\n",
    "    \"\"\"\n",
    "    can modify this function to convert the utc timestamp to whichever timezone needed\n",
    "    \"\"\"\n",
    "    #Specific UTC timestamp in microseconds (Î¼s)\n",
    "    utc_timestamp_microseconds = utc  # Example timestamp\n",
    "\n",
    "    #Converting the microseconds timestamp to seconds since the epoch\n",
    "    utc_timestamp_seconds = utc_timestamp_microseconds / 1_000_000\n",
    "\n",
    "    #Creating a datetime object from the timestamp (assumed to be in UTC)\n",
    "    utc_time = datetime.utcfromtimestamp(utc_timestamp_seconds)\n",
    "\n",
    "    #Making the UTC time aware by setting its timezone to UTC\n",
    "    utc_time = utc_time.replace(tzinfo=pytz.utc) \n",
    "\n",
    "    #Defining the target timezone (CET)\n",
    "    target_timezone = pytz.timezone('Europe/Berlin')  #Berlin is in the CET zone -> modify this to whichever other timezone required even if different from timezone of device system\n",
    "\n",
    "    #Converting to the desired timezone\n",
    "    cet_time = utc_time.astimezone(target_timezone)\n",
    "\n",
    "    return cet_time\n",
    "\n",
    "def read_avro(avro_file_path, output_dir):\n",
    "    \n",
    "    ## Read Avro file\n",
    "    reader = DataFileReader(open(avro_file_path, \"rb\"), DatumReader())\n",
    "    schema = json.loads(reader.meta.get('avro.schema').decode('utf-8'))\n",
    "    data= next(reader)\n",
    "    ## Print the Avro schema - not a necessary step. remove comments on this code section if step necessary\n",
    "    #print(schema)\n",
    "    #print(\" \")\n",
    "    ## Export sensors data to csv files\n",
    "    \n",
    "    # Accelerometer\n",
    "    acc = data[\"rawData\"][\"accelerometer\"]\n",
    "    timestamp_cet = utc_cet(acc[\"timestampStart\"]) \n",
    "    mod_acc_file = '_'.join([str(timestamp_cet).split(\"+\")[0], 'accelerometer.csv'])\n",
    "    acc_file = mod_acc_file.replace(\":\", \"_\").replace(\".\", \"_\", 1).replace(\" \", \"_\")\n",
    "    timestamp = [round(acc[\"timestampStart\"] + i * (1e6 / acc[\"samplingFrequency\"])) \n",
    "                for i in range(len(acc[\"x\"]))]\n",
    "    timestamp_CET = [utc_cet(timestamp[i])\n",
    "                for i in range(len(acc[\"x\"]))] #for every utc timestamp produced in microseconds it is converted to cet timezone\n",
    "    with open(os.path.join(output_dir, acc_file), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"unix_timestamp\", \"CET_timestamp\", \"x\", \"y\", \"z\"])\n",
    "        writer.writerows([[ts, tsc, x, y, z] for ts, tsc, x, y, z in zip(timestamp, timestamp_CET, acc[\"x\"], acc[\"y\"], acc[\"z\"])])\n",
    "    \n",
    "    # Gyroscope\n",
    "    gyro = data[\"rawData\"][\"gyroscope\"]\n",
    "    timestamp_cet = utc_cet(gyro[\"timestampStart\"]) \n",
    "    mod_gyro_file = '_'.join([str(timestamp_cet).split(\"+\")[0], 'gyroscope.csv'])\n",
    "    gyro_file = mod_gyro_file.replace(\":\", \"_\").replace(\".\", \"_\", 1).replace(\" \", \"_\") #this needs to be debugged\n",
    "    timestamp = [round(gyro[\"timestampStart\"] + i * (1e6 / gyro[\"samplingFrequency\"]))\n",
    "                for i in range(len(gyro[\"x\"]))]\n",
    "    timestamp_CET = [utc_cet(timestamp[i])\n",
    "                for i in range(len(gyro[\"x\"]))] #for every utc timestamp produced in microseconds it is converted to cet timezone\n",
    "    with open(os.path.join(output_dir, gyro_file), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"unix_timestamp\", \"CET_timestamp\", \"x\", \"y\", \"z\"])\n",
    "        writer.writerows([[ts, tsc, x, y, z] for ts, tsc, x, y, z in zip(timestamp, timestamp_CET, gyro[\"x\"], gyro[\"y\"], gyro[\"z\"])])\n",
    "    \n",
    "    # Eda\n",
    "    eda = data[\"rawData\"][\"eda\"]\n",
    "    timestamp_cet = utc_cet(eda[\"timestampStart\"])\n",
    "    mod_eda_file = '_'.join([str(timestamp_cet).split(\"+\")[0], 'eda_cet.csv'])\n",
    "    eda_file = mod_eda_file.replace(\":\", \"_\").replace(\".\", \"_\", 1).replace(\" \", \"_\")\n",
    "    timestamp = [round(eda[\"timestampStart\"] + i * (1e6 / eda[\"samplingFrequency\"])) #(1e6 / eda[\"samplingFrequency\"]) = 10^6 x (1/4) = 10^6 x 0.25s = 250,000 microseconds. Therefore all the subsequent utc timestamps generated should be timestamp start (which is in microseconds) +multiples of 250,000 microseconds and so the answers are all in microseconds\n",
    "                for i in range(len(eda[\"values\"]))]\n",
    "    timestamp_CET = [utc_cet(timestamp[i])\n",
    "                for i in range(len(eda[\"values\"]))] #for every utc timestamp produced in microseconds it is converted to cet timezone\n",
    "    with open(os.path.join(output_dir, eda_file), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"unix_timestamp\", \"CET_timestamp\", \"eda\"])\n",
    "        writer.writerows([[ts, tsc, eda] for ts, tsc, eda in zip(timestamp, timestamp_CET, eda[\"values\"])])\n",
    "\n",
    "    \n",
    "    # Temperature\n",
    "    tmp = data[\"rawData\"][\"temperature\"]\n",
    "    timestamp_cet = utc_cet(tmp[\"timestampStart\"])\n",
    "    mod_tmp_file = '_'.join([str(timestamp_cet).split(\"+\")[0], 'temperature_cet.csv'])\n",
    "    tmp_file = mod_tmp_file.replace(\":\", \"_\").replace(\".\", \"_\", 1).replace(\" \", \"_\")\n",
    "    timestamp = [round(tmp[\"timestampStart\"] + i * (1e6 / tmp[\"samplingFrequency\"]))\n",
    "                for i in range(len(tmp[\"values\"]))]\n",
    "    timestamp_CET = [utc_cet(timestamp[i])\n",
    "                for i in range(len(tmp[\"values\"]))] #for every utc timestamp produced in microseconds it is converted to cet timezone\n",
    "    with open(os.path.join(output_dir, tmp_file), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"unix_timestamp\", \"CET_timestamp\", \"temperature\"])\n",
    "        writer.writerows([[ts, tsc, tmp] for ts, tsc, tmp in zip(timestamp, timestamp_CET, tmp[\"values\"])])\n",
    "    \n",
    "    # Tags\n",
    "    tags = data[\"rawData\"][\"tags\"] #need a diff naming strategy. So - using utc timestamp on filename instead\n",
    "    file_timestamp = '_'.join([avro_file_path.split(\"\\\\\")[-1].split(\".\")[0], 'tags.csv']) #will be reusing this for systolic peaks\n",
    "    with open(os.path.join(output_dir, file_timestamp), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"tags_timestamp\"])\n",
    "        writer.writerows([[tag] for tag in tags[\"tagsTimeMicros\"]])\n",
    "    \n",
    "    # BVP\n",
    "    bvp = data[\"rawData\"][\"bvp\"]\n",
    "    timestamp_cet = utc_cet(bvp[\"timestampStart\"])\n",
    "    mod_bvp_file = '_'.join([str(timestamp_cet).split(\"+\")[0], 'bvp.csv'])\n",
    "    bvp_file = mod_bvp_file.replace(\":\", \"_\").replace(\".\", \"_\", 1).replace(\" \", \"_\")\n",
    "    timestamp = [round(bvp[\"timestampStart\"] + i * (1e6 / bvp[\"samplingFrequency\"]))\n",
    "                for i in range(len(bvp[\"values\"]))]\n",
    "    timestamp_CET = [utc_cet(timestamp[i])\n",
    "                for i in range(len(bvp[\"values\"]))] #for every utc timestamp produced in microseconds it is converted to cet timezone\n",
    "    with open(os.path.join(output_dir, bvp_file), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"unix_timestamp\", \"CET_timestamp\", \"bvp\"])\n",
    "        writer.writerows([[ts, tsc, bvp] for ts, tsc, bvp in zip(timestamp, timestamp_CET, bvp[\"values\"])])\n",
    "   \n",
    "    # Systolic peaks\n",
    "    sps = data[\"rawData\"][\"systolicPeaks\"] #need a diff naming strategy. So - using utc timestamp on filename instead as in Tags\n",
    "    file_timestamp_sps = '_'.join([avro_file_path.split(\"\\\\\")[-1].split(\".\")[0], 'systolic_peaks.csv'])\n",
    "    with open(os.path.join(output_dir, file_timestamp_sps), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"systolic_peak_timestamp\"])\n",
    "        writer.writerows([[sp] for sp in sps[\"peaksTimeNanos\"]])\n",
    "    \n",
    "    # Steps\n",
    "    steps = data[\"rawData\"][\"steps\"]\n",
    "    timestamp_cet = utc_cet(steps[\"timestampStart\"])\n",
    "    mod_steps_file = '_'.join([str(timestamp_cet).split(\"+\")[0], 'steps.csv'])\n",
    "    steps_file = mod_steps_file.replace(\":\", \"_\").replace(\".\", \"_\", 1).replace(\" \", \"_\")\n",
    "    timestamp = [round(steps[\"timestampStart\"] + i * (1e6 / steps[\"samplingFrequency\"]))\n",
    "                for i in range(len(steps[\"values\"]))]\n",
    "    timestamp_CET = [utc_cet(timestamp[i])\n",
    "                for i in range(len(steps[\"values\"]))] #for every utc timestamp produced in microseconds it is converted to cet timezone\n",
    "    with open(os.path.join(output_dir, steps_file), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"unix_timestamp\", \"CET_timestamp\", \"steps\"])\n",
    "        writer.writerows([[ts, tsc, step] for ts, tsc, step in zip(timestamp, timestamp_CET, steps[\"values\"])])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4787df02-5185-4789-bd90-5d19d7bff7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code block to reference the necessary folders\n",
    "\"\"\"\n",
    "parentfolder = input('enter the participant folder: ') \n",
    "\n",
    "\"\"\"\n",
    "names of folders to be used\n",
    "\"\"\"\n",
    "folder1 = 'empatica'\n",
    "folder2 = 'saved_figures'\n",
    "\n",
    "folder11 = 'aggr_p_min'\n",
    "folder12 = 'avro_files'\n",
    "folder13 = 'avro2csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702e88fd-a90d-4b34-9980-5128b75d2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "re-running the essential steps of the code above for files of other days\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "need to generate files for each and every avro file generated for the day. \n",
    "first generate all the new required directories\n",
    "\"\"\"\n",
    "for subfolder in os.listdir(parentfolder):\n",
    "    if subfolder.endswith('_d'):\n",
    "        for file in os.listdir(os.path.join(parentfolder, subfolder, folder1, folder12)):\n",
    "            Dir= os.mkdir(os.path.join(parentfolder, subfolder, folder1, folder13, file.split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5777e5ab-242d-4e55-bde4-518e27dfb30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\becke\\AppData\\Local\\Temp\\ipykernel_41352\\3588001253.py:15: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  utc_time = datetime.utcfromtimestamp(utc_timestamp_seconds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "now generate all the new required files to be stored within the newly created directories\n",
    "\"\"\"\n",
    "for subfolder in os.listdir(parentfolder):\n",
    "    if subfolder.endswith('_d'):\n",
    "        \n",
    "        file_list = os.listdir(os.path.join(parentfolder, subfolder, folder1, folder12))\n",
    "        op_list = os.listdir(os.path.join(parentfolder, subfolder, folder1, folder13))\n",
    "        for i in range(0,len(file_list)):\n",
    "            ipFile = os.path.join(parentfolder, subfolder, folder1, folder12, file_list[i])\n",
    "            opDir = os.path.join(parentfolder, subfolder, folder1, folder13, op_list[i])\n",
    "            read_avro(ipFile, opDir) \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89575c25-cd33-425f-b47c-a978628d5422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
